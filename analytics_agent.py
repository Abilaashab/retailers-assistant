import json
import logging
import traceback
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from enum import Enum, auto
from dataclasses import dataclass, field
from pydantic import BaseModel, Field

# Import the formatting function from response_utils
from response_utils import format_database_response

# Set up logging
logger = logging.getLogger(__name__)

# Import the execute_nl_query function from nlq.py
from nlq import execute_nl_query

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QueryStatus(Enum):
    PENDING = "pending"
    EXECUTING = "executing"
    COMPLETED = "completed"
    FAILED = "failed"

@dataclass
class QueryStep:
    """Represents a single query in the analytics pipeline."""
    query_id: str
    sql: str
    purpose: str
    status: QueryStatus = QueryStatus.PENDING
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    created_at: datetime = field(default_factory=datetime.utcnow)
    completed_at: Optional[datetime] = None

@dataclass
class AnalyticsSession:
    """Tracks the state of an analytics session."""
    session_id: str
    user_question: str
    steps: List[QueryStep] = field(default_factory=list)
    current_step: int = 0
    context: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)

    def add_step(self, sql: str, purpose: str) -> str:
        """Add a new query step to the session."""
        query_id = f"q{len(self.steps) + 1}"
        step = QueryStep(
            query_id=query_id,
            sql=sql,
            purpose=purpose
        )
        self.steps.append(step)
        self.updated_at = datetime.utcnow()
        return query_id

    def update_step_status(self, query_id: str, status: QueryStatus, result: Optional[Dict] = None, error: Optional[str] = None):
        """Update the status of a query step."""
        for step in self.steps:
            if step.query_id == query_id:
                step.status = status
                step.completed_at = datetime.utcnow()
                if result is not None:
                    step.result = result
                if error is not None:
                    step.error = error
                self.updated_at = datetime.utcnow()
                break

class AnalyticsAgent:
    """Agent for handling complex analytics queries by breaking them down into multiple SQL queries."""
    
    def __init__(self, session_id: str):
        self.session = AnalyticsSession(session_id=session_id, user_question="")
        self.llm = None  # Will be initialized when needed
        
    def analyze_question(self, question: str) -> Dict[str, Any]:
        """Analyze the question and plan the necessary queries."""
        self.session.user_question = question
        
        # Clear any existing steps
        self.session.steps = []
        
        # Add the main query step
        self.session.add_step(
            sql="",  # Will be generated by execute_nl_query
            purpose=f"Answer the question: {question}"
        )
        
        logger.info(f"[Analytics Agent] Planned {len(self.session.steps)} steps for question: {question}")
        
        return {
            "status": "success",
            "steps_planned": len(self.session.steps),
            "next_step": 0
        }
    
    def execute_next_step(self) -> Tuple[bool, Dict[str, Any]]:
        """Execute the next planned query step."""
        if not self.session.steps:
            logger.warning("[Analytics Agent] No steps to execute")
            return False, {"status": "complete", "message": "No steps to execute"}
            
        if self.session.current_step >= len(self.session.steps):
            logger.info("[Analytics Agent] All steps completed")
            return False, {"status": "complete", "message": "All steps completed"}
            
        step = self.session.steps[self.session.current_step]
        logger.info(f"[Analytics Agent] Executing step {self.session.current_step + 1}: {step.purpose}")
        logger.info(f"[Analytics Agent] Query: {step.sql}")
        
        try:
            # Execute the query using nlq - pass the original question, not the SQL
            logger.info("[Analytics Agent] Calling execute_nl_query...")
            # Use the purpose which contains the original question, or fall back to step.sql if needed
            nl_question = step.purpose.replace("Answer the question: ", "") if step.purpose.startswith("Answer the question:") else step.sql
            result = execute_nl_query(nl_question)
            
            # Log the query result
            logger.info(f"[Analytics Agent] Query result - Success: {result.get('success', False)}")
            if not result.get("success", False):
                logger.error(f"[Analytics Agent] Query failed: {result.get('error', 'Unknown error')}")
            
            # Store the result
            step.status = QueryStatus.COMPLETED
            step.result = result
            self.session.current_step += 1
            
            # Check if there are more steps
            has_next = self.session.current_step < len(self.session.steps)
            logger.info(f"[Analytics Agent] Step completed. Has next: {has_next}")
            return has_next, {"status": "success", "step": self.session.current_step - 1}
            
        except Exception as e:
            error_msg = f"Error executing step {self.session.current_step + 1}: {str(e)}"
            logger.error(f"[Analytics Agent] {error_msg}\n{traceback.format_exc()}")
            step.status = QueryStatus.FAILED
            step.error = error_msg
            return False, {"status": "error", "error": error_msg, "step": self.session.current_step}
    
    def get_final_response(self) -> Dict[str, Any]:
        """Generate a final response based on all query results using Gemini 1.5 Flash."""
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.messages import HumanMessage
        import os
        from dotenv import load_dotenv
        
        # Load environment variables
        load_dotenv()
        
        completed_steps = [s for s in self.session.steps if s.status == QueryStatus.COMPLETED]
        failed_steps = [s for s in self.session.steps if s.status == QueryStatus.FAILED]
        
        # Default response
        response = {
            "session_id": self.session.session_id,
            "question": self.session.user_question,
            "status": "completed" if not failed_steps else "partial",
            "steps_completed": len(completed_steps),
            "steps_failed": len(failed_steps),
            "context": self.session.context,
            "confidence": 0.8 if not failed_steps else 0.5,
            "data": None
        }
        
        # Process completed steps to extract and format results
        if completed_steps:
            last_step = completed_steps[-1]
            if last_step.result and last_step.result.get('success', False):
                data = last_step.result.get('data', [])
                response['data'] = data
                
                try:
                    # Initialize Gemini 1.5 Flash
                    llm = ChatGoogleGenerativeAI(
                        model="gemini-1.5-flash",
                        google_api_key=os.getenv('GOOGLE_API_KEY'),
                        temperature=0.2
                    )
                    
                    # Create a prompt for the LLM
                    prompt = f"""
                    Based on the following data, provide a clear and concise answer to the user's query.
                    
                    User Query: {self.session.user_question}
                    
                    Data:
                    {json.dumps(data, indent=2, default=str)}
                    
                    Guidelines:
                    - Be concise and to the point
                    - Use natural language
                    - Format numbers appropriately (e.g., 1,000 instead of 1000)
                    - If the data shows quantities, mention the units
                    - If no relevant data is found, say so clearly
                    
                    Response:
                    """
                    
                    # Get response from Gemini
                    # llm_response = llm.invoke([HumanMessage(content=prompt)])
                    # response['answer'] = llm_response.content.strip()
                    # console.log(prompt)
                    
                except Exception as e:
                    logger.error(f"Error generating response with Gemini: {str(e)}")
                    # Fallback to default formatting
                    if data:
                        if isinstance(data, list) and data and 'remaining' in data[0]:
                            response['answer'] = f"The remaining quantity is {data[0]['remaining']} units."
                        else:
                            response['answer'] = f"Here's the data you requested: {json.dumps(data, default=str, indent=2)}"
                    else:
                        response['answer'] = "No data found matching your query."
        
        return response

def analytics_agent_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """Node function for the analytics agent in the workflow."""
    if state.get("processed", False):
        return {"agent_output": {"message": "Query already processed", "success": False}}
    
    query = state.get("query", "")
    session_id = state.get("session_id", f"sess_{int(datetime.utcnow().timestamp())}")
    
    logger.info(f"Analytics Agent processing: {query}")
    
    try:
        logger.info(f"[Analytics Agent] Initializing agent for session: {session_id}")
        agent = AnalyticsAgent(session_id=session_id)
        
        # Step 1: Analyze the question and plan queries
        logger.info(f"[Analytics Agent] Analyzing question: {query}")
        analysis = agent.analyze_question(query)
        logger.info(f"[Analytics Agent] Analysis complete. Planned {len(agent.session.steps)} query steps.")
        
        # Step 2: Execute all planned queries
        logger.info("[Analytics Agent] Starting query execution...")
        step_count = 0
        while True:
            step_count += 1
            logger.info(f"[Analytics Agent] Executing step {step_count}...")
            has_next, result = agent.execute_next_step()
            logger.info(f"[Analytics Agent] Step {step_count} result: {result}")
            if not has_next:
                logger.info("[Analytics Agent] No more steps to execute.")
                break
        
        # Step 3: Generate final response
        logger.info("[Analytics Agent] Generating final response...")
        response = agent.get_final_response()
        logger.info(f"[Analytics Agent] Response generated. Status: {response.get('status', 'unknown')}")
        logger.info(f"[Analytics Agent] Response content: {response}")
        
        return {
            "agent_output": {
                "success": True,
                "response": response,
                "data": response.get("data"),
                "session_id": session_id
            }
        }
        
    except Exception as e:
        error_msg = f"Error in analytics agent: {str(e)}"
        logger.error(f"[Analytics Agent] {error_msg}\n{traceback.format_exc()}")
        logger.error(f"[Analytics Agent] State at time of error: {json.dumps(state, default=str, indent=2)}")
        return {
            "agent_output": {
                "success": False,
                "error": error_msg,
                "type": "analytics_agent_error"
            },
            "error": error_msg
        }
